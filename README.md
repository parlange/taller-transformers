# Taller: Vision Transformers ðŸ¤–
## ðŸ’» Facultad de IngenierÃ­a (CIEP-FI)
## ðŸ›ï¸ Universidad AutÃ³noma de San Luis PotosÃ­ (UASLP)

### ðŸ“š Diapositivas de Transformers (Lucas Beyer, autor del ViT)
>### ðŸ”— http://lucasb.eyer.be/transformer
>### ðŸ““ https://arxiv.org/pdf/2010.11929

---

### ðŸ¿ Attention in Transformers: Concepts and Code in PyTorch (deeplearning.ai)
>### ðŸ”— https://learn.deeplearning.ai/courses/attention-in-transformers-concepts-and-code-in-pytorch

---

### 0ï¸âƒ£ ClasificaciÃ³n de dÃ­gitos MNIST con Vision Transformer (ViT) 
>#### Fine-tuning: ImageNet con 21,000 clases (vit-base-patch16-224-in21k)
>#### Downstream task: 10,000 imÃ¡genes de MNIST (10 clases)
>#### Tutorial de ViT-MNIST generado con ChatGPT 4o ðŸ¤–

#### ðŸ“” Google Colab: [https://colab.research.google.com](https://colab.research.google.com/drive/1sBlPiOHjvGERI6gtPGUe-z1BilWtcn6D?usp=sharing)

---
